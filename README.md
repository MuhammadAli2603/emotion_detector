ğŸ¤– Emotion Detector: Realâ€‘Time Facial Expression Recognition

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MuhammadAli2603/emotion-detection/blob/main/test.ipynb)  
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)  
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)]()  
[![TensorFlow](https://img.shields.io/badge/TensorFlow-%3E%3D2.0-orange.svg)]()  
[![OpenCV](https://img.shields.io/badge/OpenCV-%3E%3D4.0-yellow.svg)]()  
[![Keras](https://img.shields.io/badge/Keras-%3E%3D2.3-red.svg)]()

Project Overview
An endâ€‘toâ€‘end realâ€‘time emotion recognition system built with Deep Learning:

- Backbone: MobileNet preâ€‘trained on ImageNet, fineâ€‘tuned on FER2013.
- Face Detection: Haar cascade classifier (ali.xml).
- Inference: Realâ€‘time video capture + emotion prediction via OpenCV & Keras.
- Demo: â€œOpen in Colabâ€ notebook runs everythingâ€”no local install required!
Why this matters
â€¢ Interactive: See live emotion labels overlaid on webcam feed.
â€¢ Compact: MobileNet head achieves high accuracy with low latency.
â€¢ Extensible: Swap in other models, add data augmentation, or expand emotion classes.
## ğŸ“‚ Repository Structure

```text
emotion-detection/
â”œâ”€â”€ test.py                â† Realâ€‘time webcam demo
â”œâ”€â”€ train.py               â† Training & fineâ€‘tuning script
â”œâ”€â”€ emotion_model.h5       â† Preâ€‘trained Keras model
â”œâ”€â”€ ali.xml                â† Haar cascade face detector
â”œâ”€â”€ requirements.txt       â† Python dependencies
â”œâ”€â”€ README.md              â† Project overview & instructions
â””â”€â”€ LICENSE                â† MIT License

````` 

Quickstart

1ï¸âƒ£ Run Demo in Colab (No Setup!)
   1. Click Open in Colab above.
   2. Runtime â†’ Run all to:
      - Download dependencies
      - Load face detector & model
      - Launch webcam demo in notebook

2ï¸âƒ£ Run Locally
```
git clone https://github.com/MuhammadAli2603/emotion-detection.git
cd emotion-detection
python3 -m venv .venv && source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

# Run realâ€‘time demo:
python test.py
```
Usage Highlights
â€¢ Realâ€‘Time Inference:
  ```bash
  python test.py
  ```

â€¢ Training:
  ```bash
  python train.py
  ```
Sample Results
Emotion    | Example Frame
-----------|----------------
Happy ğŸ˜Š   | docs/happy_sample.png
Sad ğŸ˜¢     | docs/sad_sample.png
Surprise ğŸ˜²| docs/surprise_sample.png
Angry ğŸ˜    | docs/angry_sample.png
Critical Considerations
â€¢ Class Imbalance: FER2013 is skewedâ€”consider class weighting or augmentation.
â€¢ Lighting & Resolution: Good lighting improves detection & classification accuracy.
â€¢ Model Choice: Try lighter backbones (e.g. MobileNetV2) for faster mobile deployment.
Contributing
1. Fork this repo
2. Create a feature branch (git checkout -b feature/awesome)
3. Make your changes & add tests
4. Commit & push to your fork
5. Open a Pull Request describing your improvements
License
This project is released under the MIT License. See LICENSE for details.
